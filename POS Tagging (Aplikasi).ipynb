{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "# Load the model from the pickle file\n",
    "with open('model_Baum_Welch.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Extract model parameters\n",
    "probabilitas_awal = model['probabilitas_awal']\n",
    "probabilitas_transisi = model['probabilitas_transisi']\n",
    "probabilitas_emisi = model['probabilitas_emisi']\n",
    "probabilitas_emisi_kata_kosong = model['probabilitas_emisi_kata_kosong']\n",
    "pos_tags = ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'SCONJ', 'VERB', 'X']\n",
    "pos_freq = model['pos_freq']\n",
    "vocab_size = model['vocab_size']\n",
    "\n",
    "# Define the POS tags\n",
    "pos_tags = ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'SCONJ', 'VERB', 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritma Forward\n",
    "def algoritma_forward(sentence, probabilitas_emisi, probabilitas_transisi, probabilitas_awal, pos_tags, probabilitas_emisi_kata_kosong):\n",
    "    alpha = [{}]\n",
    "    for pos in pos_tags:\n",
    "        alpha[0][pos] = probabilitas_awal.get(pos, 0) * probabilitas_emisi.get((sentence[0], pos), probabilitas_emisi_kata_kosong[pos])\n",
    "        \n",
    "    for t in range(1, len(sentence)):\n",
    "        alpha.append({})\n",
    "        for pos in pos_tags:\n",
    "            alpha[t][pos] = sum(alpha[t-1][prev_pos] * probabilitas_transisi.get((prev_pos, pos), 0) * probabilitas_emisi.get((sentence[t], pos), probabilitas_emisi_kata_kosong[pos]) for prev_pos in pos_tags)\n",
    "    \n",
    "    return alpha\n",
    "\n",
    "# Algoritma Backward\n",
    "def algoritma_backward(sentence, probabilitas_emisi, probabilitas_transisi, pos_tags, probabilitas_emisi_kata_kosong):\n",
    "    beta = [{} for _ in range(len(sentence))]\n",
    "    \n",
    "    # Inisialisasi beta pada waktu t = T\n",
    "    for pos in pos_tags:\n",
    "        beta[-1][pos] = 1\n",
    "    \n",
    "    # Iterasi mundur dari t = T-1 ke t = 0\n",
    "    for t in range(len(sentence) - 2, -1, -1):\n",
    "        for pos in pos_tags:\n",
    "            beta[t][pos] = sum(beta[t + 1][next_pos] * probabilitas_transisi.get((pos, next_pos), 0) * probabilitas_emisi.get((sentence[t + 1], next_pos), probabilitas_emisi_kata_kosong[next_pos]) for next_pos in pos_tags)\n",
    "    \n",
    "    return beta\n",
    "\n",
    "def expectation_step(sentence, alpha, beta, probabilitas_emisi, probabilitas_transisi, pos_tags, probabilitas_emisi_kata_kosong):\n",
    "    T = len(sentence)\n",
    "    gamma = [{} for _ in range(T)]\n",
    "    ksi = [{} for _ in range(T - 1)]\n",
    "    \n",
    "    # menghitung gamma\n",
    "    for t in range(T):\n",
    "        normalization_factor = sum(alpha[t][pos] * beta[t][pos] for pos in pos_tags)\n",
    "        for pos in pos_tags:\n",
    "            gamma[t][pos] = (alpha[t][pos] * beta[t][pos]) / normalization_factor\n",
    "    \n",
    "    # menghitung ksi\n",
    "    for t in range(T - 1):\n",
    "        normalization_factor = sum(\n",
    "            alpha[t][pos1] * probabilitas_transisi.get((pos1, pos2), 0) *\n",
    "            probabilitas_emisi.get((sentence[t + 1], pos2), probabilitas_emisi_kata_kosong.get(pos2, 0)) * beta[t + 1][pos2]\n",
    "            for pos1 in pos_tags for pos2 in pos_tags\n",
    "        )\n",
    "        for pos1 in pos_tags:\n",
    "            ksi[t][pos1] = {}\n",
    "            for pos2 in pos_tags:\n",
    "                ksi[t][pos1][pos2] = (\n",
    "                    alpha[t][pos1] * probabilitas_transisi.get((pos1, pos2), 0) *  # Ensure it returns 0 if missing\n",
    "                    probabilitas_emisi.get((sentence[t + 1], pos2), probabilitas_emisi_kata_kosong.get(pos2, 0)) * beta[t + 1][pos2]\n",
    "                ) / normalization_factor if normalization_factor != 0 else 0\n",
    "    \n",
    "    return gamma, ksi\n",
    "\n",
    "def maximization_step(gamma, ksi, sentence, pos_tags):\n",
    "    probabilitas_awal_baru = {pos: gamma[0][pos] for pos in pos_tags}\n",
    "    \n",
    "    probabilitas_transisi_baru = {}\n",
    "    for pos1 in pos_tags:\n",
    "        for pos2 in pos_tags:\n",
    "            a = sum(ksi[t][pos1][pos2] for t in range(len(ksi)))\n",
    "            b = sum(gamma[t][pos1] for t in range(len(gamma)))\n",
    "            if b != 0:\n",
    "                probabilitas_transisi_baru[(pos1, pos2)] = a / b\n",
    "            else:\n",
    "                probabilitas_transisi_baru[(pos1, pos2)] = 0\n",
    "    \n",
    "    # Menghitung probabilitas emisi baru\n",
    "    probabilitas_emisi_baru = {}\n",
    "    for pos in pos_tags:\n",
    "        for word in set(sentence):\n",
    "            a = sum(gamma[t][pos] for t in range(len(sentence)) if sentence[t] == word)\n",
    "            b = sum(gamma[t][pos] for t in range(len(sentence)))\n",
    "            probabilitas_emisi_baru[(word, pos)] = a / b if b != 0 else 0\n",
    "    \n",
    "    return probabilitas_awal_baru, probabilitas_transisi_baru, probabilitas_emisi_baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Forward Algorithm dengan Maximization Step\n",
    "# def algoritma_forward_max(sentence, probabilitas_awal, probabilitas_transisi, probabilitas_emisi):\n",
    "#     # Inisialisasi alpha\n",
    "#     alpha = [{}]\n",
    "#     for pos in pos_tags:\n",
    "#         alpha[0][pos] = probabilitas_awal[pos] * probabilitas_emisi[pos].get(sentence[0], 0)\n",
    "        \n",
    "#     # Iterasi untuk menghitung alpha\n",
    "#     for t in range(1, len(sentence)):\n",
    "#         alpha.append({})\n",
    "#         for pos2 in pos_tags:\n",
    "#             alpha[t][pos2] = sum(alpha[t-1][pos1] * probabilitas_transisi.get((pos1, pos2), 0) * probabilitas_emisi[pos2].get(sentence[t], 0) for pos1 in pos_tags)\n",
    "            \n",
    "#     return alpha\n",
    "\n",
    "# # Backward Algorithm dengan Maximization Step\n",
    "# def algoritma_backward_max(sentence, probabilitas_transisi, probabilitas_emisi):\n",
    "#     # Inisialisasi beta\n",
    "#     beta = [{} for _ in range(len(sentence))]\n",
    "#     for pos in pos_tags:\n",
    "#         beta[len(sentence)-1][pos] = 1\n",
    "        \n",
    "#     # Iterasi untuk menghitung beta\n",
    "#     for t in range(len(sentence)-2, -1, -1):\n",
    "#         for pos1 in pos_tags:\n",
    "#             beta[t][pos1] = sum(probabilitas_transisi.get((pos1, pos2), 0) * probabilitas_emisi[pos2].get(sentence[t+1], 0) * beta[t+1][pos2] for pos2 in pos_tags)\n",
    "            \n",
    "#     return beta\n",
    "\n",
    "# # Expectation Step setelah Maximization: Menghitung gamma dan ksi\n",
    "# def expectation_step_max(sentence, alpha, beta, probabilitas_transisi, probabilitas_emisi):\n",
    "#     gamma = [{} for _ in range(len(alpha))]\n",
    "#     ksi = [{} for _ in range(len(sentence) - 1)]\n",
    "    \n",
    "#     for t in range(len(alpha)):\n",
    "#         normalization_factor = sum(alpha[t][pos] * beta[t][pos] for pos in pos_tags)\n",
    "#         for pos in pos_tags:\n",
    "#             gamma[t][pos] = (alpha[t][pos] * beta[t][pos]) / normalization_factor\n",
    "    \n",
    "#     for t in range(len(sentence) - 1):\n",
    "#         normalization_factor = sum(alpha[t][pos1] * probabilitas_transisi.get((pos1, pos2), 0) * probabilitas_emisi[pos2].get(sentence[t+1], 0) * \n",
    "#                         beta[t+1][pos2] for pos1 in pos_tags for pos2 in pos_tags)\n",
    "#         for pos1 in pos_tags:\n",
    "#             ksi[t][pos1] = {}\n",
    "#             for pos2 in pos_tags:\n",
    "#                 ksi[t][pos1][pos2] = (alpha[t][pos1] * probabilitas_transisi.get((pos1, pos2), 0) * probabilitas_emisi[pos2].get(sentence[t+1], 0) * \n",
    "#                                         beta[t+1][pos2]) / normalization_factor\n",
    "    \n",
    "#     return gamma, ksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilai Likelihood (L): 9.845216324889176e-12\n",
      "Iteration 1: Likelihood = 0.000000000, Change in Likelihood = inf\n",
      "Iteration 2: Likelihood = 0.000000007, Change in Likelihood = 0.000000007\n",
      "\n",
      "Final Likelihood: 7.426076694279858e-09\n"
     ]
    }
   ],
   "source": [
    "# Function to clear the frame\n",
    "def clear_frame():\n",
    "    for widget in root.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "# Function to predict POS tags for a new sentence\n",
    "def predict_pos_tagging():\n",
    "    clear_frame()\n",
    "\n",
    "    # Add title\n",
    "    title_label = tk.Label(root, text=\"Aplikasi Prediksi Pos Tagging Bahasa Jawa\", font=(\"Helvetica\", 16, \"bold\"), bg=\"dodger blue\", fg=\"white\",padx=10, pady=5)\n",
    "    title_label.pack(pady=(10, 5), padx=10)\n",
    "\n",
    "    # Create input prompt\n",
    "    prompt_label = tk.Label(root, text=\"Masukkan kalimat untuk prediksi POS tagging:\")\n",
    "    prompt_label.pack(pady=(10, 0))\n",
    "\n",
    "    # Input field\n",
    "    input_field = tk.Entry(root, width=50)\n",
    "    input_field.pack(pady=(5, 5), padx=10)\n",
    "\n",
    "    # Add note about the maximum number of words\n",
    "    note_label = tk.Label(root, text=\"Catatan : Tidak memberikan kalimat yang panjang (Max Kata = 122)\", fg=\"red\")\n",
    "    note_label.pack(pady=(0, 5))\n",
    "\n",
    "    # Add result label\n",
    "    result_label = tk.Label(root, text=\"Hasil prediksi:\")\n",
    "    result_label.pack(pady=(10, 0))\n",
    "    \n",
    "    # Frame to hold result box and scrollbar\n",
    "    result_frame = tk.Frame(root)\n",
    "    result_frame.pack(pady=(5, 10), padx=10, fill=\"both\", expand=True)\n",
    "\n",
    "    # Scrollbar for the result box\n",
    "    scrollbar = tk.Scrollbar(result_frame)\n",
    "    scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "\n",
    "    # Result box (Text widget)\n",
    "    result_box = tk.Text(result_frame, wrap=\"word\", height=10, width=50, yscrollcommand=scrollbar.set)\n",
    "    result_box.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "    scrollbar.config(command=result_box.yview)\n",
    "\n",
    "    # Function to process the input\n",
    "    def process_input():\n",
    "        kalimat_testing = input_field.get()\n",
    "        if kalimat_testing:\n",
    "            kalimat_testing = kalimat_testing.lower()\n",
    "            test_sentence = kalimat_testing.split()\n",
    "\n",
    "            # Baum-Welch process\n",
    "            test_sentences = [test_sentence]\n",
    "            result_text = \"\"\n",
    "            for kalimat in test_sentences:\n",
    "                sentence = [kata for kata in kalimat]\n",
    "\n",
    "                alpha = algoritma_forward(sentence, probabilitas_emisi, probabilitas_transisi, probabilitas_awal, pos_tags, probabilitas_emisi_kata_kosong)\n",
    "\n",
    "                beta = algoritma_backward(sentence, probabilitas_emisi, probabilitas_transisi, pos_tags, probabilitas_emisi_kata_kosong)\n",
    "\n",
    "                gamma, ksi = expectation_step(sentence, alpha, beta, probabilitas_emisi, probabilitas_transisi, pos_tags, probabilitas_emisi_kata_kosong)\n",
    "\n",
    "                probabilitas_awal_baru, probabilitas_transisi_baru, probabilitas_emisi_baru = maximization_step(gamma, ksi, sentence, pos_tags)\n",
    "\n",
    "                alpha_max = algoritma_forward(sentence, probabilitas_emisi_baru, probabilitas_transisi_baru, probabilitas_awal_baru, pos_tags, probabilitas_emisi_kata_kosong)\n",
    "\n",
    "                beta_max = algoritma_backward(sentence, probabilitas_emisi_baru, probabilitas_transisi_baru, pos_tags, probabilitas_emisi_kata_kosong)\n",
    "\n",
    "                likelihood = sum(alpha_max[-1].get(pos, 0) * beta_max[-1].get(pos, 0) for pos in pos_tags)\n",
    "                    \n",
    "\n",
    "                print(\"Nilai Likelihood (L):\", likelihood)\n",
    "\n",
    "                gamma_max, ksi_max = expectation_step(sentence, alpha_max, beta_max, probabilitas_emisi_baru, probabilitas_transisi_baru, pos_tags, probabilitas_emisi_kata_kosong)\n",
    "\n",
    "                threshold = 1e-3\n",
    "                likelihood_diff = float('inf')\n",
    "                prev_likelihood = 0\n",
    "\n",
    "                iteration = 0\n",
    "\n",
    "                while likelihood_diff > threshold:\n",
    "                    iteration += 1\n",
    "\n",
    "                    alpha_max = algoritma_forward(sentence, probabilitas_emisi_baru, probabilitas_transisi_baru, probabilitas_awal_baru, pos_tags, probabilitas_emisi_kata_kosong)\n",
    "                    beta_max = algoritma_backward(sentence, probabilitas_emisi_baru, probabilitas_transisi_baru, pos_tags, probabilitas_emisi_kata_kosong)\n",
    "\n",
    "                    gamma_max, ksi_max = expectation_step(sentence, alpha_max, beta_max, probabilitas_emisi_baru, probabilitas_transisi_baru, pos_tags, probabilitas_emisi_kata_kosong)\n",
    "\n",
    "                    probabilitas_awal_baru, probabilitas_transisi_baru, probabilitas_emisi_baru = maximization_step(gamma_max, ksi_max, sentence, pos_tags)\n",
    "                    likelihood = sum(alpha_max[-1][pos] * beta_max[-1][pos] for pos in pos_tags)\n",
    "                    current_likelihood = likelihood\n",
    "                    if iteration >= 2:\n",
    "                        likelihood_diff = current_likelihood - prev_likelihood\n",
    "                        prev_likelihood = current_likelihood\n",
    "                    else:\n",
    "                        prev_likelihood = current_likelihood\n",
    "                    print(f\"Iteration {iteration}: Likelihood = {current_likelihood:.9f}, Change in Likelihood = {likelihood_diff:.9f}\")\n",
    "\n",
    "                print(\"\\nFinal Likelihood:\", likelihood)\n",
    "\n",
    "                predicted_tags = []\n",
    "                for t in range(len(sentence)):\n",
    "                    kata = sentence[t]\n",
    "                    if kata in ['.', ',', '!', '?', ':', ';', '(', ')', '[', ']', '{', '}', '\"', \"'\", '-']:\n",
    "                        predicted_tags.append('PUNCT')\n",
    "                    elif kata in ['$', '%', '@', '&', '#', '*']:\n",
    "                        predicted_tags.append('SYM')\n",
    "                    else:\n",
    "                        predicted_tags.append(max(gamma_max[t], key=gamma_max[t].get))\n",
    "\n",
    "                # Add to the result text\n",
    "                result_text += \"\\n\".join(f\"{word}: {tag}\" for word, tag in zip(sentence, predicted_tags)) + \"\\n\"\n",
    "\n",
    "            result_box.delete(\"1.0\", tk.END)  # Clear the box before displaying new results\n",
    "            result_box.insert(tk.END, f\"Hasil Prediksi:\\n{result_text}\")\n",
    "\n",
    "    # Frame to hold the buttons\n",
    "    button_frame = tk.Frame(root)\n",
    "    button_frame.pack(pady=5)\n",
    "\n",
    "    # Predict button\n",
    "    predict_button = tk.Button(button_frame, text=\"Prediksi\", command=process_input, width=15, height=2, bg=\"dodger blue\", fg=\"white\", font=(\"Helvetica\", 12, \"bold\"), bd=2, relief=\"solid\", highlightbackground=\"white\")\n",
    "    predict_button.pack(side=\"left\", padx=10)\n",
    "\n",
    "    # New button to restart the prediction\n",
    "    def new_prediction():\n",
    "        predict_pos_tagging()\n",
    "\n",
    "    new_button = tk.Button(button_frame, text=\"Hapus\", command=new_prediction, width=15, height=2, bg=\"dodger blue\", fg=\"white\", font=(\"Helvetica\", 12, \"bold\"), bd=2, relief=\"solid\", highlightbackground=\"white\")\n",
    "    new_button.pack(side=\"left\", padx=10)\n",
    "\n",
    "# Create the GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Aplikasi POS Tagging\")\n",
    "\n",
    "predict_pos_tagging()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buat Cari Warna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "\n",
    "\n",
    "class ScrolledFrame(Frame):\n",
    "    def __init__(self, master=None, *args, **kwargs):\n",
    "        top = Frame(master)  # create top frame, containing all things\n",
    "        # attach scrollbars\n",
    "        vscroll = Scrollbar(top)\n",
    "        vscroll.pack(side='right', fill='y')\n",
    "        hscroll = Scrollbar(top, orient='horizontal')\n",
    "        hscroll.pack(side='bottom', fill='x')\n",
    "        # hack: insert self into scrollable canvas\n",
    "        canvas = Canvas(top, highlightthickness=0)\n",
    "        canvas.pack(expand=True, fill='both')\n",
    "        super().__init__(master=canvas, *args, **kwargs)  # create\n",
    "        canvas.create_window(0,0, window=self,\n",
    "                             anchor='nw', tags='frame')  # insert\n",
    "        # add a hack to rebuild scrollable area size\n",
    "        canvas.bind('<Configure>', self.__set_scroll)\n",
    "        # cross-bind scrolling\n",
    "        vscroll['command'] = canvas.yview\n",
    "        canvas['yscrollcommand'] = vscroll.set\n",
    "        hscroll['command'] = canvas.xview\n",
    "        canvas['xscrollcommand'] = hscroll.set\n",
    "        # attach hierarchically\n",
    "        self._top = top\n",
    "        self._top._vscroll = vscroll\n",
    "        self._top._hscroll = hscroll\n",
    "        self._top._canvas = canvas\n",
    "\n",
    "    def pack(self, *args, **kwargs):\n",
    "        '''\n",
    "        A wrapper over tkinter's pack\n",
    "        '''\n",
    "        return self._top.pack(*args, **kwargs) # pack topmost\n",
    "\n",
    "    def __set_scroll(self, event=None):\n",
    "        canvas = self._top._canvas\n",
    "        canvas.config(scrollregion=canvas.bbox('frame'))\n",
    "\n",
    "def showcolors(colors):\n",
    "    colors = colors[:]\n",
    "    root = Tk()\n",
    "    root.title('Tkinter colors showcase')\n",
    "    Label(root, text='Double click to copy to clipboard').pack(fill='x')\n",
    "    top = ScrolledFrame(root)\n",
    "    colnum = int((len(colors)/3) ** 0.5)\n",
    "    row = 0\n",
    "    while colors:\n",
    "        chunk, colors = colors[:colnum], colors[colnum:]\n",
    "        for col, color in enumerate(chunk):\n",
    "            lab = Label(top, text=color, bg=color)\n",
    "            lab.grid(row=row, column=col, sticky='wens')\n",
    "            lab.bind('<Double-1>', _clipboard_copy(lab))\n",
    "            lab.bind('<Enter>', lambda ev, lab=lab: lab.config(fg='white'))\n",
    "            lab.bind('<Leave>', lambda ev, lab=lab: lab.config(fg='black'))\n",
    "        row += 1\n",
    "    top.pack(expand=True, fill='both')\n",
    "    root.mainloop()\n",
    "\n",
    "def _clipboard_copy(inst):\n",
    "    def wrapper(event):\n",
    "        inst.clipboard_clear()\n",
    "        inst.clipboard_append(inst['text'])\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "\n",
    "COLORS = ['snow', 'ghost white', 'white smoke', 'gainsboro', 'floral white', 'old lace',\n",
    "          'linen', 'antique white', 'papaya whip', 'blanched almond', 'bisque', 'peach puff',\n",
    "          'navajo white', 'lemon chiffon', 'mint cream', 'azure', 'alice blue', 'lavender',\n",
    "          'lavender blush', 'misty rose', 'dark slate gray', 'dim gray', 'slate gray',\n",
    "          'light slate gray', 'gray', 'light grey', 'midnight blue', 'navy', 'cornflower blue', 'dark slate blue',\n",
    "          'slate blue', 'medium slate blue', 'light slate blue', 'medium blue', 'royal blue',  'blue',\n",
    "          'dodger blue', 'deep sky blue', 'sky blue', 'light sky blue', 'steel blue', 'light steel blue',\n",
    "          'light blue', 'powder blue', 'pale turquoise', 'dark turquoise', 'medium turquoise', 'turquoise',\n",
    "          'cyan', 'light cyan', 'cadet blue', 'medium aquamarine', 'aquamarine', 'dark green', 'dark olive green',\n",
    "          'dark sea green', 'sea green', 'medium sea green', 'light sea green', 'pale green', 'spring green',\n",
    "          'lawn green', 'medium spring green', 'green yellow', 'lime green', 'yellow green',\n",
    "          'forest green', 'olive drab', 'dark khaki', 'khaki', 'pale goldenrod', 'light goldenrod yellow',\n",
    "          'light yellow', 'yellow', 'gold', 'light goldenrod', 'goldenrod', 'dark goldenrod', 'rosy brown',\n",
    "          'indian red', 'saddle brown', 'sandy brown',\n",
    "          'dark salmon', 'salmon', 'light salmon', 'orange', 'dark orange',\n",
    "          'coral', 'light coral', 'tomato', 'orange red', 'red', 'hot pink', 'deep pink', 'pink', 'light pink',\n",
    "          'pale violet red', 'maroon', 'medium violet red', 'violet red',\n",
    "          'medium orchid', 'dark orchid', 'dark violet', 'blue violet', 'purple', 'medium purple',\n",
    "          'thistle', 'snow2', 'snow3',\n",
    "          'snow4', 'seashell2', 'seashell3', 'seashell4', 'AntiqueWhite1', 'AntiqueWhite2',\n",
    "          'AntiqueWhite3', 'AntiqueWhite4', 'bisque2', 'bisque3', 'bisque4', 'PeachPuff2',\n",
    "          'PeachPuff3', 'PeachPuff4', 'NavajoWhite2', 'NavajoWhite3', 'NavajoWhite4',\n",
    "          'LemonChiffon2', 'LemonChiffon3', 'LemonChiffon4', 'cornsilk2', 'cornsilk3',\n",
    "          'cornsilk4', 'ivory2', 'ivory3', 'ivory4', 'honeydew2', 'honeydew3', 'honeydew4',\n",
    "          'LavenderBlush2', 'LavenderBlush3', 'LavenderBlush4', 'MistyRose2', 'MistyRose3',\n",
    "          'MistyRose4', 'azure2', 'azure3', 'azure4', 'SlateBlue1', 'SlateBlue2', 'SlateBlue3',\n",
    "          'SlateBlue4', 'RoyalBlue1', 'RoyalBlue2', 'RoyalBlue3', 'RoyalBlue4', 'blue2', 'blue4',\n",
    "          'DodgerBlue2', 'DodgerBlue3', 'DodgerBlue4', 'SteelBlue1', 'SteelBlue2',\n",
    "          'SteelBlue3', 'SteelBlue4', 'DeepSkyBlue2', 'DeepSkyBlue3', 'DeepSkyBlue4',\n",
    "          'SkyBlue1', 'SkyBlue2', 'SkyBlue3', 'SkyBlue4', 'LightSkyBlue1', 'LightSkyBlue2',\n",
    "          'LightSkyBlue3', 'LightSkyBlue4', 'SlateGray1', 'SlateGray2', 'SlateGray3',\n",
    "          'SlateGray4', 'LightSteelBlue1', 'LightSteelBlue2', 'LightSteelBlue3',\n",
    "          'LightSteelBlue4', 'LightBlue1', 'LightBlue2', 'LightBlue3', 'LightBlue4',\n",
    "          'LightCyan2', 'LightCyan3', 'LightCyan4', 'PaleTurquoise1', 'PaleTurquoise2',\n",
    "          'PaleTurquoise3', 'PaleTurquoise4', 'CadetBlue1', 'CadetBlue2', 'CadetBlue3',\n",
    "          'CadetBlue4', 'turquoise1', 'turquoise2', 'turquoise3', 'turquoise4', 'cyan2', 'cyan3',\n",
    "          'cyan4', 'DarkSlateGray1', 'DarkSlateGray2', 'DarkSlateGray3', 'DarkSlateGray4',\n",
    "          'aquamarine2', 'aquamarine4', 'DarkSeaGreen1', 'DarkSeaGreen2', 'DarkSeaGreen3',\n",
    "          'DarkSeaGreen4', 'SeaGreen1', 'SeaGreen2', 'SeaGreen3', 'PaleGreen1', 'PaleGreen2',\n",
    "          'PaleGreen3', 'PaleGreen4', 'SpringGreen2', 'SpringGreen3', 'SpringGreen4',\n",
    "          'green2', 'green3', 'green4', 'chartreuse2', 'chartreuse3', 'chartreuse4',\n",
    "          'OliveDrab1', 'OliveDrab2', 'OliveDrab4', 'DarkOliveGreen1', 'DarkOliveGreen2',\n",
    "          'DarkOliveGreen3', 'DarkOliveGreen4', 'khaki1', 'khaki2', 'khaki3', 'khaki4',\n",
    "          'LightGoldenrod1', 'LightGoldenrod2', 'LightGoldenrod3', 'LightGoldenrod4',\n",
    "          'LightYellow2', 'LightYellow3', 'LightYellow4', 'yellow2', 'yellow3', 'yellow4',\n",
    "          'gold2', 'gold3', 'gold4', 'goldenrod1', 'goldenrod2', 'goldenrod3', 'goldenrod4',\n",
    "          'DarkGoldenrod1', 'DarkGoldenrod2', 'DarkGoldenrod3', 'DarkGoldenrod4',\n",
    "          'RosyBrown1', 'RosyBrown2', 'RosyBrown3', 'RosyBrown4', 'IndianRed1', 'IndianRed2',\n",
    "          'IndianRed3', 'IndianRed4', 'sienna1', 'sienna2', 'sienna3', 'sienna4', 'burlywood1',\n",
    "          'burlywood2', 'burlywood3', 'burlywood4', 'wheat1', 'wheat2', 'wheat3', 'wheat4', 'tan1',\n",
    "          'tan2', 'tan4', 'chocolate1', 'chocolate2', 'chocolate3', 'firebrick1', 'firebrick2',\n",
    "          'firebrick3', 'firebrick4', 'brown1', 'brown2', 'brown3', 'brown4', 'salmon1', 'salmon2',\n",
    "          'salmon3', 'salmon4', 'LightSalmon2', 'LightSalmon3', 'LightSalmon4', 'orange2',\n",
    "          'orange3', 'orange4', 'DarkOrange1', 'DarkOrange2', 'DarkOrange3', 'DarkOrange4',\n",
    "          'coral1', 'coral2', 'coral3', 'coral4', 'tomato2', 'tomato3', 'tomato4', 'OrangeRed2',\n",
    "          'OrangeRed3', 'OrangeRed4', 'red2', 'red3', 'red4', 'DeepPink2', 'DeepPink3', 'DeepPink4',\n",
    "          'HotPink1', 'HotPink2', 'HotPink3', 'HotPink4', 'pink1', 'pink2', 'pink3', 'pink4',\n",
    "          'LightPink1', 'LightPink2', 'LightPink3', 'LightPink4', 'PaleVioletRed1',\n",
    "          'PaleVioletRed2', 'PaleVioletRed3', 'PaleVioletRed4', 'maroon1', 'maroon2',\n",
    "          'maroon3', 'maroon4', 'VioletRed1', 'VioletRed2', 'VioletRed3', 'VioletRed4',\n",
    "          'magenta2', 'magenta3', 'magenta4', 'orchid1', 'orchid2', 'orchid3', 'orchid4', 'plum1',\n",
    "          'plum2', 'plum3', 'plum4', 'MediumOrchid1', 'MediumOrchid2', 'MediumOrchid3',\n",
    "          'MediumOrchid4', 'DarkOrchid1', 'DarkOrchid2', 'DarkOrchid3', 'DarkOrchid4',\n",
    "          'purple1', 'purple2', 'purple3', 'purple4', 'MediumPurple1', 'MediumPurple2',\n",
    "          'MediumPurple3', 'MediumPurple4', 'thistle1', 'thistle2', 'thistle3', 'thistle4',\n",
    "          'gray1', 'gray2', 'gray3', 'gray4', 'gray5', 'gray6', 'gray7', 'gray8', 'gray9', 'gray10',\n",
    "          'gray11', 'gray12', 'gray13', 'gray14', 'gray15', 'gray16', 'gray17', 'gray18', 'gray19',\n",
    "          'gray20', 'gray21', 'gray22', 'gray23', 'gray24', 'gray25', 'gray26', 'gray27', 'gray28',\n",
    "          'gray29', 'gray30', 'gray31', 'gray32', 'gray33', 'gray34', 'gray35', 'gray36', 'gray37',\n",
    "          'gray38', 'gray39', 'gray40', 'gray42', 'gray43', 'gray44', 'gray45', 'gray46', 'gray47',\n",
    "          'gray48', 'gray49', 'gray50', 'gray51', 'gray52', 'gray53', 'gray54', 'gray55', 'gray56',\n",
    "          'gray57', 'gray58', 'gray59', 'gray60', 'gray61', 'gray62', 'gray63', 'gray64', 'gray65',\n",
    "          'gray66', 'gray67', 'gray68', 'gray69', 'gray70', 'gray71', 'gray72', 'gray73', 'gray74',\n",
    "          'gray75', 'gray76', 'gray77', 'gray78', 'gray79', 'gray80', 'gray81', 'gray82', 'gray83',\n",
    "          'gray84', 'gray85', 'gray86', 'gray87', 'gray88', 'gray89', 'gray90', 'gray91', 'gray92',\n",
    "          'gray93', 'gray94', 'gray95', 'gray97', 'gray98', 'gray99']\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    showcolors(COLORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buat Cari Font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import font\n",
    "\n",
    "root = Tk()\n",
    "root.title('Font Families')\n",
    "fonts=list(font.families())\n",
    "fonts.sort()\n",
    "\n",
    "def populate(frame):\n",
    "    '''Put in the fonts'''\n",
    "    listnumber = 1\n",
    "    for i, item in enumerate(fonts):\n",
    "        label = \"listlabel\" + str(listnumber)\n",
    "        label = Label(frame,text=item,font=(item, 16))\n",
    "        label.grid(row=i)\n",
    "        label.bind(\"<Button-1>\",lambda e,item=item:copy_to_clipboard(item))\n",
    "        listnumber += 1\n",
    "\n",
    "def copy_to_clipboard(item):\n",
    "    root.clipboard_clear()\n",
    "    root.clipboard_append(\"font=('\" + item.lstrip('@') + \"', 12)\")\n",
    "\n",
    "def onFrameConfigure(canvas):\n",
    "    '''Reset the scroll region to encompass the inner frame'''\n",
    "    canvas.configure(scrollregion=canvas.bbox(\"all\"))\n",
    "\n",
    "canvas = Canvas(root, borderwidth=0, background=\"#ffffff\")\n",
    "frame = Frame(canvas, background=\"#ffffff\")\n",
    "vsb = Scrollbar(root, orient=\"vertical\", command=canvas.yview)\n",
    "canvas.configure(yscrollcommand=vsb.set)\n",
    "\n",
    "vsb.pack(side=\"right\", fill=\"y\")\n",
    "canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "canvas.create_window((4,4), window=frame, anchor=\"nw\")\n",
    "\n",
    "frame.bind(\"<Configure>\", lambda event, canvas=canvas: onFrameConfigure(canvas))\n",
    "\n",
    "populate(frame)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kodingan di bawah enggak fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import simpledialog, messagebox\n",
    "import pickle\n",
    "\n",
    "# Load the model results from the pickle file\n",
    "with open('model_results.pkl', 'rb') as file:\n",
    "    model_results = pickle.load(file)\n",
    "\n",
    "# Define the POS tags\n",
    "pos_tags = ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'SCONJ', 'VERB', 'X']\n",
    "\n",
    "# Function to clear the frame\n",
    "def clear_frame():\n",
    "    for widget in root.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "# Function to predict POS tags for a new sentence\n",
    "def predict_pos_tagging():\n",
    "    clear_frame()\n",
    "\n",
    "    # Create input prompt\n",
    "    prompt_label = tk.Label(root, text=\"Masukkan kalimat untuk prediksi POS tagging:\")\n",
    "    prompt_label.pack(pady=10)\n",
    "\n",
    "    # Input field\n",
    "    input_field = tk.Entry(root, width=50)\n",
    "    input_field.pack(pady=10)\n",
    "\n",
    "    # Result label\n",
    "    result_label = tk.Label(root, text=\"\", justify=\"left\")\n",
    "    result_label.pack(pady=10)\n",
    "\n",
    "    # Function to process the input\n",
    "    def process_input():\n",
    "        kalimat_testing = input_field.get()\n",
    "        if kalimat_testing:\n",
    "            kalimat_testing = kalimat_testing.lower()\n",
    "            test_sentence = kalimat_testing.split()\n",
    "\n",
    "            # Aggregate results from all sentences in the model results\n",
    "            hasil_Keseluruhan = []\n",
    "            for result in model_results:\n",
    "                for word, tag in result:\n",
    "                    if word in test_sentence:\n",
    "                        hasil_Keseluruhan.append((word, tag))\n",
    "\n",
    "            # Remove duplicates while preserving order\n",
    "            dilihat = set()\n",
    "            hasil_prediksi = [(word, tag) for word, tag in hasil_Keseluruhan if not (word in dilihat or dilihat.add(word))]\n",
    "\n",
    "            # Display the predicted POS tags\n",
    "            if hasil_prediksi:\n",
    "                result_text = \"\\n\".join(f\"{word}: {tag}\" for word, tag in hasil_prediksi)\n",
    "                result_label.config(text=f\"Hasil Prediksi: {result_text}\")\n",
    "                \n",
    "                # Check for words that could not be predicted\n",
    "                kata_prediksi = {word for word, tag in hasil_prediksi}\n",
    "                kata_baru = [word for word in test_sentence if word not in kata_prediksi]\n",
    "                if kata_baru:\n",
    "                    missing_text = \", \".join(word for word in kata_baru)\n",
    "                    result_label.config(text=f\"Hasil Prediksi: {result_text}\\n\\nKata yang tidak bisa diprediksi:\\n{missing_text}\")\n",
    "            else:\n",
    "                result_label.config(text=\"Tidak ada kata yang ditemukan di kalimat input.\")\n",
    "\n",
    "    # Predict button\n",
    "    predict_button = tk.Button(root, text=\"Predict\", command=process_input)\n",
    "    predict_button.pack(pady=5)\n",
    "\n",
    "    # New button to restart the prediction\n",
    "    def new_prediction():\n",
    "        predict_pos_tagging()\n",
    "\n",
    "    new_button = tk.Button(root, text=\"New\", command=new_prediction)\n",
    "    new_button.pack(pady=5)\n",
    "\n",
    "# Create the GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"POS Tagging Predictor\")\n",
    "\n",
    "predict_pos_tagging()\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Likelihood = 0.000912043, Change in Likelihood = inf\n",
      "Iteration 2: Likelihood = 0.021741489, Change in Likelihood = 0.020829446\n",
      "Iteration 3: Likelihood = 0.288917827, Change in Likelihood = 0.267176338\n",
      "Iteration 4: Likelihood = 0.680785446, Change in Likelihood = 0.391867619\n",
      "Iteration 5: Likelihood = 0.870912357, Change in Likelihood = 0.190126911\n",
      "Iteration 6: Likelihood = 0.960590191, Change in Likelihood = 0.089677834\n",
      "Iteration 7: Likelihood = 0.993148174, Change in Likelihood = 0.032557982\n",
      "Iteration 8: Likelihood = 0.999492888, Change in Likelihood = 0.006344714\n",
      "Iteration 9: Likelihood = 0.999974916, Change in Likelihood = 0.000482028\n",
      "Iteration 10: Likelihood = 0.999999851, Change in Likelihood = 0.000024935\n",
      "\n",
      "Final Likelihood: 0.9999998505927273\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Algoritma Forward\n",
    "def algoritma_forward(sentence, probabilitas_emisi, probabilitas_transisi, probabilitas_awal, pos_tags, probabilitas_emisi_kata_kosong):\n",
    "    alpha = [{} for _ in range(len(sentence))]\n",
    "    for pos in pos_tags:\n",
    "        alpha[0][pos] = probabilitas_awal.get(pos, 0) * probabilitas_emisi.get((sentence[0], pos), probabilitas_emisi_kata_kosong[pos])\n",
    "        \n",
    "    for t in range(1, len(sentence)):\n",
    "        alpha.append({})\n",
    "        for pos in pos_tags:\n",
    "            alpha[t][pos] = sum(alpha[t-1][prev_pos] * probabilitas_transisi.get((prev_pos, pos), 0) * probabilitas_emisi.get((sentence[t], pos), probabilitas_emisi_kata_kosong[pos]) for prev_pos in pos_tags)\n",
    "    \n",
    "    return alpha\n",
    "\n",
    "# Algoritma Backward\n",
    "def algoritma_backward(sentence, probabilitas_emisi, probabilitas_transisi, pos_tags, probabilitas_emisi_kata_kosong):\n",
    "    beta = [{} for _ in range(len(sentence))]\n",
    "    \n",
    "    # Inisialisasi beta pada waktu t = T\n",
    "    for pos in pos_tags:\n",
    "        beta[-1][pos] = 1\n",
    "    \n",
    "    # Iterasi mundur dari t = T-1 ke t = 0\n",
    "    for t in range(len(sentence) - 2, -1, -1):\n",
    "        for pos in pos_tags:\n",
    "            beta[t][pos] = sum(beta[t + 1][next_pos] * probabilitas_transisi.get((pos, next_pos), 0) * probabilitas_emisi.get((sentence[t + 1], next_pos), probabilitas_emisi_kata_kosong[next_pos]) for next_pos in pos_tags)\n",
    "    \n",
    "    return beta\n",
    "\n",
    "def expectation_step(sentence, alpha, beta, probabilitas_emisi, probabilitas_transisi, pos_tags, pos_freq, vocab_size):\n",
    "    T = len(sentence)\n",
    "    gamma = [{} for _ in range(T)]\n",
    "    ksi = [{} for _ in range(T - 1)]\n",
    "    \n",
    "    # menghitung gamma\n",
    "    for t in range(T):\n",
    "        normalization_factor = sum(alpha[t][pos] * beta[t][pos] for pos in pos_tags)\n",
    "        for pos in pos_tags:\n",
    "            gamma[t][pos] = (alpha[t][pos] * beta[t][pos]) / normalization_factor\n",
    "    \n",
    "    # menghitung ksi\n",
    "    for t in range(T - 1):\n",
    "        normalization_factor = sum(\n",
    "            alpha[t][pos1] * probabilitas_transisi.get((pos1, pos2), (1 / (pos_freq[pos1] + vocab_size))) *\n",
    "            probabilitas_emisi.get((sentence[t + 1], pos2), (1 / (pos_freq[pos2] + vocab_size))) * beta[t + 1][pos2]\n",
    "            for pos1 in pos_tags for pos2 in pos_tags\n",
    "        )\n",
    "        for pos1 in pos_tags:\n",
    "            ksi[t][pos1] = {}\n",
    "            for pos2 in pos_tags:\n",
    "                ksi[t][pos1][pos2] = (\n",
    "                    alpha[t][pos1] * probabilitas_transisi.get((pos1, pos2), (1 / (pos_freq[pos1] + vocab_size))) *\n",
    "                    probabilitas_emisi.get((sentence[t + 1], pos2), (1 / (pos_freq[pos2] + vocab_size))) * beta[t + 1][pos2]\n",
    "                ) / normalization_factor\n",
    "    \n",
    "    return gamma, ksi\n",
    "\n",
    "def maximization_step(gamma, ksi, sentence, pos_tags):\n",
    "    probabilitas_awal_baru = {pos: gamma[0][pos] for pos in pos_tags}\n",
    "    \n",
    "    probabilitas_transisi_baru = {}\n",
    "    for pos1 in pos_tags:\n",
    "        for pos2 in pos_tags:\n",
    "            a = sum(ksi[t][pos1][pos2] for t in range(len(ksi)))\n",
    "            b = sum(gamma[t][pos1] for t in range(len(gamma)))\n",
    "            probabilitas_transisi_baru[(pos1, pos2)] = a / b\n",
    "    \n",
    "    probabilitas_emisi_baru = {}\n",
    "    for pos in pos_tags:\n",
    "        probabilitas_emisi_baru[pos] = {}\n",
    "        for word in sentence:\n",
    "            a = sum(gamma[t][pos] for t in range(len(gamma)) if sentence[t] == word)\n",
    "            b = sum(gamma[t][pos] for t in range(len(gamma)))\n",
    "            probabilitas_emisi_baru[pos][word] = a / b\n",
    "    \n",
    "    return probabilitas_awal_baru, probabilitas_transisi_baru, probabilitas_emisi_baru\n",
    "\n",
    "# Forward Algorithm dengan Maximization Step\n",
    "def algoritma_forward_max(sentence, probabilitas_awal, probabilitas_transisi, probabilitas_emisi):\n",
    "    # Inisialisasi alpha\n",
    "    alpha = [{}]\n",
    "    for pos in pos_tags:\n",
    "        alpha[0][pos] = probabilitas_awal[pos] * probabilitas_emisi[pos].get(sentence[0], 0)\n",
    "        \n",
    "    # Iterasi untuk menghitung alpha\n",
    "    for t in range(1, len(sentence)):\n",
    "        alpha.append({})\n",
    "        for pos2 in pos_tags:\n",
    "            alpha[t][pos2] = sum(alpha[t-1][pos1] * probabilitas_transisi.get((pos1, pos2), 0) * probabilitas_emisi[pos2].get(sentence[t], 0) for pos1 in pos_tags)\n",
    "            \n",
    "    return alpha\n",
    "\n",
    "# Backward Algorithm dengan Maximization Step\n",
    "def algoritma_backward_max(sentence, probabilitas_transisi, probabilitas_emisi):\n",
    "    # Inisialisasi beta\n",
    "    beta = [{} for _ in range(len(sentence))]\n",
    "    for pos in pos_tags:\n",
    "        beta[len(sentence)-1][pos] = 1\n",
    "        \n",
    "    # Iterasi untuk menghitung beta\n",
    "    for t in range(len(sentence)-2, -1, -1):\n",
    "        for pos1 in pos_tags:\n",
    "            beta[t][pos1] = sum(probabilitas_transisi.get((pos1, pos2), 0) * probabilitas_emisi[pos2].get(sentence[t+1], 0) * beta[t+1][pos2] for pos2 in pos_tags)\n",
    "            \n",
    "    return beta\n",
    "\n",
    "# Expectation Step setelah Maximization: Menghitung gamma dan ksi\n",
    "def expectation_step_max(sentence, alpha, beta, probabilitas_transisi, probabilitas_emisi):\n",
    "    gamma = [{} for _ in range(len(alpha))]\n",
    "    ksi = [{} for _ in range(len(sentence) - 1)]\n",
    "    \n",
    "    for t in range(len(alpha)):\n",
    "        normalization_factor = sum(alpha[t][pos] * beta[t][pos] for pos in pos_tags)\n",
    "        for pos in pos_tags:\n",
    "            gamma[t][pos] = (alpha[t][pos] * beta[t][pos]) / normalization_factor\n",
    "    \n",
    "    for t in range(len(sentence) - 1):\n",
    "        normalization_factor = sum(alpha[t][pos1] * probabilitas_transisi.get((pos1, pos2), 0) * probabilitas_emisi[pos2].get(sentence[t+1], 0) * \n",
    "                        beta[t+1][pos2] for pos1 in pos_tags for pos2 in pos_tags)\n",
    "        for pos1 in pos_tags:\n",
    "            ksi[t][pos1] = {}\n",
    "            for pos2 in pos_tags:\n",
    "                ksi[t][pos1][pos2] = (alpha[t][pos1] * probabilitas_transisi.get((pos1, pos2), 0) * probabilitas_emisi[pos2].get(sentence[t+1], 0) * \n",
    "                                        beta[t+1][pos2]) / normalization_factor\n",
    "    \n",
    "    return gamma, ksi\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "# Load the model from the pickle file\n",
    "with open('model_Baum_Welch.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Extract model parameters\n",
    "probabilitas_awal = model['probabilitas_awal']\n",
    "probabilitas_transisi = model['probabilitas_transisi']\n",
    "probabilitas_emisi = model['probabilitas_emisi']\n",
    "probabilitas_emisi_kata_kosong = model['probabilitas_emisi_kata_kosong']\n",
    "pos_tags = ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'SCONJ', 'VERB', 'X']\n",
    "pos_freq = model['pos_freq']\n",
    "vocab_size = model['vocab_size']\n",
    "\n",
    "# Define the POS tags\n",
    "pos_tags = ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'SCONJ', 'VERB', 'X']\n",
    "\n",
    "# Function to clear the frame\n",
    "def clear_frame():\n",
    "    for widget in root.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "# Function to predict POS tags for a new sentence\n",
    "def predict_pos_tagging():\n",
    "    clear_frame()\n",
    "\n",
    "    # Add title\n",
    "    title_label = tk.Label(root, text=\"Aplikasi Prediksi Pos Tagging Bahasa Jawa\", font=(\"Helvetica\", 16, \"bold\"), bg=\"dodger blue\", fg=\"white\",padx=10, pady=5)\n",
    "    title_label.pack(pady=(10, 5), padx=10)\n",
    "\n",
    "    # Create input prompt\n",
    "    prompt_label = tk.Label(root, text=\"Masukkan kalimat untuk prediksi POS tagging:\")\n",
    "    prompt_label.pack(pady=(10, 0))\n",
    "\n",
    "    # Input field\n",
    "    input_field = tk.Entry(root, width=50)\n",
    "    input_field.pack(pady=(5, 20), padx=10)\n",
    "\n",
    "    # Add result label\n",
    "    result_label = tk.Label(root, text=\"Hasil prediksi:\")\n",
    "    result_label.pack(pady=(10, 0))\n",
    "    \n",
    "    # Frame to hold result box and scrollbar\n",
    "    result_frame = tk.Frame(root)\n",
    "    result_frame.pack(pady=(5, 10), padx=10, fill=\"both\", expand=True)\n",
    "\n",
    "    # Scrollbar for the result box\n",
    "    scrollbar = tk.Scrollbar(result_frame)\n",
    "    scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "\n",
    "    # Result box (Text widget)\n",
    "    result_box = tk.Text(result_frame, wrap=\"word\", height=10, width=50, yscrollcommand=scrollbar.set)\n",
    "    result_box.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "    scrollbar.config(command=result_box.yview)\n",
    "\n",
    "    # Function to process the input\n",
    "    def process_input():\n",
    "        kalimat_testing = input_field.get()\n",
    "        if kalimat_testing:\n",
    "            kalimat_testing = kalimat_testing.lower()\n",
    "            test_sentence = kalimat_testing.split()\n",
    "\n",
    "            # Baum-Welch process\n",
    "            test_sentences = [test_sentence]\n",
    "            result_text = \"\"\n",
    "            for kalimat in test_sentences:\n",
    "                sentence = [kata for kata in kalimat]\n",
    "\n",
    "                alpha = algoritma_forward(sentence, probabilitas_emisi, probabilitas_transisi, probabilitas_awal, pos_tags, probabilitas_emisi_kata_kosong)\n",
    "                # print(\"Forward Algorithm :\")\n",
    "                # for t in range(len(sentence)):\n",
    "                #     print(\"Alpha (t) : \", alpha[t])\n",
    "                beta = algoritma_backward(sentence, probabilitas_emisi, probabilitas_transisi, pos_tags, probabilitas_emisi_kata_kosong)\n",
    "                # print(\"\\nBackward Algorithm :\")\n",
    "                # for t in range(len(sentence)):\n",
    "                #     print(\"Beta (t) : \", beta[t])\n",
    "                gamma, ksi = expectation_step(sentence, alpha, beta, probabilitas_emisi, probabilitas_transisi, pos_tags, pos_freq, vocab_size)\n",
    "                probabilitas_awal_baru, probabilitas_transisi_baru, probabilitas_emisi_baru = maximization_step(gamma, ksi, sentence, pos_tags)\n",
    "\n",
    "                alpha_max = algoritma_forward_max(sentence, probabilitas_awal_baru, probabilitas_transisi_baru, probabilitas_emisi_baru)\n",
    "                beta_max = algoritma_backward_max(sentence, probabilitas_transisi_baru, probabilitas_emisi_baru)\n",
    "                likelihood = sum(alpha[-1].get(pos, 0) * beta_max[-1].get(pos, 0) for pos in pos_tags)\n",
    "                gamma_max, ksi_max = expectation_step_max(sentence, alpha_max, beta_max, probabilitas_transisi_baru, probabilitas_emisi_baru)\n",
    "\n",
    "                threshold = 1e-4\n",
    "                likelihood_diff = float('inf')\n",
    "                prev_likelihood = 0\n",
    "                iteration = 0\n",
    "\n",
    "                while likelihood_diff > threshold:\n",
    "                    iteration += 1\n",
    "                    alpha_max = algoritma_forward_max(sentence, probabilitas_awal_baru, probabilitas_transisi_baru, probabilitas_emisi_baru)\n",
    "                    beta_max = algoritma_backward_max(sentence, probabilitas_transisi_baru, probabilitas_emisi_baru)\n",
    "                    gamma_max, ksi_max = expectation_step_max(sentence, alpha_max, beta_max, probabilitas_transisi_baru, probabilitas_emisi_baru)\n",
    "                    probabilitas_awal_baru, probabilitas_transisi_baru, probabilitas_emisi_baru = maximization_step(gamma_max, ksi_max, sentence, pos_tags)\n",
    "                    likelihood = sum(alpha_max[-1][pos] * beta_max[-1][pos] for pos in pos_tags)\n",
    "                    current_likelihood = likelihood\n",
    "                    if iteration >= 2:\n",
    "                        likelihood_diff = current_likelihood - prev_likelihood\n",
    "                        prev_likelihood = current_likelihood\n",
    "                    else:\n",
    "                        prev_likelihood = current_likelihood\n",
    "                    print(f\"Iteration {iteration}: Likelihood = {current_likelihood:.9f}, Change in Likelihood = {likelihood_diff:.9f}\")\n",
    "\n",
    "                print(\"\\nFinal Likelihood:\", likelihood)\n",
    "\n",
    "                predicted_tags = []\n",
    "                for t in range(len(sentence)):\n",
    "                    kata = sentence[t]\n",
    "                    if kata in ['.', ',', '!', '?', ':', ';', '(', ')', '[', ']', '{', '}', '\"', \"'\", '-']:\n",
    "                        predicted_tags.append('PUNCT')\n",
    "                    elif kata in ['$', '%', '@', '&', '#', '*']:\n",
    "                        predicted_tags.append('SYM')\n",
    "                    else:\n",
    "                        predicted_tags.append(max(gamma_max[t], key=gamma_max[t].get))\n",
    "\n",
    "                # Add to the result text\n",
    "                result_text += \"\\n\".join(f\"{word}: {tag}\" for word, tag in zip(sentence, predicted_tags)) + \"\\n\"\n",
    "\n",
    "            result_box.delete(\"1.0\", tk.END)  # Clear the box before displaying new results\n",
    "            result_box.insert(tk.END, f\"Hasil Prediksi:\\n{result_text}\")\n",
    "\n",
    "    # Frame to hold the buttons\n",
    "    button_frame = tk.Frame(root)\n",
    "    button_frame.pack(pady=5)\n",
    "\n",
    "    # Predict button\n",
    "    predict_button = tk.Button(button_frame, text=\"Prediksi\", command=process_input, width=15, height=2, bg=\"dodger blue\", fg=\"white\", font=(\"Helvetica\", 12, \"bold\"), bd=2, relief=\"solid\", highlightbackground=\"white\")\n",
    "    predict_button.pack(side=\"left\", padx=10)\n",
    "\n",
    "    # New button to restart the prediction\n",
    "    def new_prediction():\n",
    "        predict_pos_tagging()\n",
    "\n",
    "    new_button = tk.Button(button_frame, text=\"Hapus\", command=new_prediction, width=15, height=2, bg=\"dodger blue\", fg=\"white\", font=(\"Helvetica\", 12, \"bold\"), bd=2, relief=\"solid\", highlightbackground=\"white\")\n",
    "    new_button.pack(side=\"left\", padx=10)\n",
    "\n",
    "# Create the GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"POS Tagging Predictor\")\n",
    "\n",
    "predict_pos_tagging()\n",
    "\n",
    "root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
